# Docker Logging Stack: Promtail + Loki + Grafana

This guide explains how to set up a lightweight log aggregation and visualization stack using:

- **Promtail** – collects logs from containers
- **Loki** – stores logs in a time-series format (like Prometheus but for logs)
- **Grafana** – visualizes logs and metrics in one place

---

## Prerequisites

- Docker and Docker Compose installed

- Internet access to pull images

- Docker daemon configured to use `json-file` log driver (default)
  
  ```bash
  # the following like should be listed.
  Logging Driver: json-file
  ```

---

## Directory Structure

```bash
loki-logging/
├── docker-compose.yml
├── loki-config.yml
└── promtail-config.yml
```

---

## Step 1: Create `docker-compose.yml`

```yaml
services:

  loki:
    image: grafana/loki:2.9.0
    container_name: loki
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/loki-config.yml
    volumes:
      - ./loki-data:/loki
      - ./loki-config.yml:/etc/loki/loki-config.yml
    restart: unless-stopped

  promtail:
    image: grafana/promtail:2.9.0
    container_name: promtail
    volumes:
      - ./promtail-config.yml:/etc/promtail/promtail-config.yml
      - /var/log:/var/log
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /etc/machine-id:/etc/machine-id:ro
      - /etc/hostname:/etc/hostname:ro
    command: -config.file=/etc/promtail/promtail-config.yml
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    restart: unless-stopped
```

---

## Step 2: Create `loki-config.yml`

```yaml
# Simplified Loki configuration for a single-binary demo.
# All data is stored locally on the filesystem.

auth_enabled: false

server:
  http_listen_port: 3100
  grpc_listen_port: 9096

# Configures the ingester component, which writes incoming log data.
ingester:
  wal:
    enabled: true
    dir: /loki/wal
  lifecycler:
    ring:
      kvstore:
        store: inmemory
      replication_factor: 1
  chunk_idle_period: 5m
  max_chunk_age: 1h

# Defines the storage schema and backend.
schema_config:
  configs:
    - from: 2024-01-01
      store: boltdb-shipper
      object_store: filesystem
      schema: v13
      index:
        prefix: index_
        period: 24h

# Configures where Loki stores its data (indexes and chunks).
storage_config:
  boltdb_shipper:
    active_index_directory: /loki/index
    cache_location: /loki/boltdb-cache
  filesystem:
    directory: /loki/chunks

# Explicitly configure the compactor's working directory.
compactor:
  working_directory: /loki/compactor
  shared_store: filesystem

# Manages retention settings for stored logs.
table_manager:
  retention_deletes_enabled: true
  retention_period: 168h # Retain logs for 7 days.

# Sets operational limits.
limits_config:
  enforce_metric_name: false
  reject_old_samples: true
  reject_old_samples_max_age: 168h

# Default query lookback period.
chunk_store_config:
  max_look_back_period: 0s
```

---

## Step 3: Create `promtail-config.yml`

```yaml
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  - job_name: docker-logs
    static_configs:
      - targets:
          - localhost
        labels:
          job: docker
          __path__: /var/lib/docker/containers/*/*.log
```

---

## Step 4: Launch the Stack

Run from inside the `loki-logging/` folder:

```bash
docker compose up -d
```

---

## Step 5: Access Grafana and Configure

| Tool    | URL                   | Default Credentials |
| ------- | --------------------- | ------------------- |
| Grafana | http://localhost:3000 | admin / admin       |
| Loki    | http://localhost:3100 | N/A                 |

### Configure Loki as a Data Source

1. Login to Grafana
2. Go to **Settings → Data Sources**
3. Add a new **Loki** data source
4. Set URL to: `http://loki:3100`
5. Click **Save & Test**

---

## Step 6: Explore Logs

1. Navigate to **Explore** in Grafana

2. Choose **Loki** as the data source

3. Use a query like:
   
   ```logql
   {job="docker"}
   ```

4. Use filters for container name, time range, log level, etc.

---

## Validation

- Logs should appear from your running Docker containers
- You can correlate logs with time, service, or container name

---

## Clean Up

```bash
docker compose down
```

---

## Tips

- Add custom labels in `promtail-config.yml` to tag logs by container, env, etc.
- Use log queries in Grafana dashboards for alerting or investigations
- Logs are collected from `json-file`, so ensure containers are not using another logging driver

---
